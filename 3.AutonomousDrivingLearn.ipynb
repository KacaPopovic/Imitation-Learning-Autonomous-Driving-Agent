{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Autonomous Driving (Part 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, the goal is to use the training data from the assignment Autonomous Driving (Part 1) for learning to drive autonomously. For that reason, we will use the car racing example from [Gymnasium](https://gymnasium.farama.org). As showed in the last assignment, Gym is a framework for developing reinforcement learning approaches. It supports different types of agents. Here, we will focus on vehicles.\n",
    "\n",
    "*Important*: You need to install [Gymnasium](https://gymnasium.farama.org) in your system. The installation can be done with pip or by installing from the sources. More information at [https://pypi.org/project/gymnasium/](https://pypi.org/project/gymnasium/)).\n",
    "\n",
    "*Important*: The Python version of Gym and the Python version of PyTorch has to be the same. This is an important requirement for creating the inference pipeline function.\n",
    "\n",
    "Note that all scripts should be self-contained and executed on *any* machine that has required libraries installed.\n",
    "\n",
    "The solutions of the assignment can be delivered as Python Notebooks or .py files. The visual results shall be delivered as pdf- or image-files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Car Racing Model Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, a car drives on a track in a racing environment. The car can turn left, right, accelerate or decelerate. The input is an image with 96x96 pixels or 96x84, if you removed the black bar on the bottom of the image. In addition, rewards are given based on the driving behavior. We are not interested in the rewards in this task. The aim of this exercise is to make use of the training data from part 1 to train a deep neural network to control the vehicle. \n",
    "\n",
    "*Task Output*: The training set of 5000 car racing images should be split into 60% training, 20% validation and 20% test samples. All subsets should include consecutive frames. The 20% test samples should include a maneuver (accelerate, decelerate, go-right/left). The neural network architecture can be chosen based on the previous classification assignment on MNIST (CNN model). However, the output of the network should be a softmax with 5 classes (accelerate, decelerate, turn left, turn right, no actions). At this point, data augmentation should not be used during training. The output of the exercise should be a plot of the training, validation and test set loss over time and the accuracy over time. The model has to be trained with [early stopping](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/) using _min_delta=0.0_ and _patience=3_.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**. The data augmentation should be dynamically implemented, i.e it is applied when the data from the mini-batch is loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation for Car Racing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is an extension of the previous one. Here, the deep neural network has to be trained with data augmentation. The same data split from part 1 will be applied here.\n",
    "\n",
    "*Task Output*: Repeat the training process with data augmentation. Each augmentation should be applied with probability 20% inside the mini-batch loading. The augmentations that have to be implemented are horizontal flipping and random rotation (up to 20 degrees). The output of the exercise should be a plot of the training, validation and test set loss over time and the accuracy over time. The model has to be trained with early stopping using _min_delta=0.0_ and _patience=3_. Finally, the loss and accuracy of training with and without augmentation should be visualized in the same plot.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**. The data augmentation should be dynamically implemented, i.e it is applied when the data from the mini-batch is loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mono-Color Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, the input images will be converted to gray-scale. Then the model will be trained on the new input data. The motivation of this exercise is to examine whether the color is necessary to train the model.\n",
    "\n",
    "*Task Output*: Repeat the training process with gray-scale images instead of RGB data. For that purpose, the 5000 images have to be converted into gray-scale off-line or on-line when fetching a mini-batch. The training should be conducted without augmentation. The output of the exercise should be a plot of the training, validation and test set loss over time and the accuracy over time. The model has to be trained with early stopping using _min_delta=0.0_ and _patience=3_. Finally, the loss and accuracy of training with RGB and gray-scale images should be visualized in the same plot.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**. The data augmentation should be dynamically implemented, i.e it is applied when the mini-batch is loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
