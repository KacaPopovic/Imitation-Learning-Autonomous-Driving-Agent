{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# Autonomous Driving (Part 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "#  C:\\Users\\Admin\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\box2d>"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Instalation of gymnasium libraries\n",
    "\n",
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "gif_url = 'https://www.gymlibrary.dev/_images/car_racing.gif'\n",
    "\n",
    "response = requests.get(gif_url)\n",
    "\n",
    "# if it worked - you will be able to open this gid\n",
    "\n",
    "with open('mygif.gif', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "display(Image(filename='mygif.gif'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A car drives a route in a racing environment. The car can turn left, right, accelerate or decelerate. The input is an image with 96x96 pixels. In addition, rewards are given based on the driving behavior. We are not interested in the rewards in this task.\n",
    " \n",
    "*Output*: A training set of at least 5000 images should be generated. You can make of the [car_racing.py](https://github.com/openai/gym/blob/master/gym/envs/box2d/car_racing.py) example from the [Gym examples](https://www.gymlibrary.dev/environments/box2d/car_racing/)  to setup a playing simulator. By playing the in the simulator, you could create 5000 frames and corresponding ground-truth. The ground-truth is simply the control option. The ground-truth can be stored as one-hot vector. The data should include diversity because they will be later used for training a deep neural network.\n",
    "\n",
    "I included my modification of the car_racing.py in the repository. Generated images and labels are in file: action_shapshots.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the generated caring car data and the respective ground-truth data will be visualized (e.g. the first 30 images). The visualization should take place after representing the data in PyTorch format. In addition, horizontal and vertical data augmentation are implemented in the data loader. Finally, an additional augmentation for changing the street color from gray to brown is implemented too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r\"C:\\Users\\Admin\\Desktop\\fau\\second semester\\ml lab\\assigment 2\\Imitation-Learning-Autonomous-Driving-Agent\\action_snapshots0.xlsx\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "image_paths = df['Snapshot'].values\n",
    "labels = df['Action'].apply(eval).values\n",
    "\n",
    "def transform_label(label):\n",
    "    if label == [0.0, 0.0, 0.0]:\n",
    "        return 0\n",
    "    elif label == [-1.0, 0.0, 0.0]:\n",
    "        return 1\n",
    "    elif label == [1.0, 0.0, 0.0]:\n",
    "        return 2\n",
    "    elif label == [0.0, 1.0, 0.0]:\n",
    "        return 3\n",
    "    elif label == [0.0, 0.0, 0.8]:\n",
    "        return 4\n",
    "    elif sum([1 for i in label if i != 0.0]) > 1:\n",
    "        return 5\n",
    "    else:\n",
    "        return 0  # Default to 0 if none of the above conditions match\n",
    "\n",
    "\n",
    "discrete_labels = np.array([transform_label(label) for label in labels])\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Path: {image_paths[i]}, Label: {discrete_labels[i]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure image paths are strings\n",
    "image_paths = [str(path) for path in image_paths]\n",
    "\n",
    "# Convert the paths to absolute paths if necessary\n",
    "base_path = r'C:\\Users\\Admin\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\box2d'  # Replace with the base path of your relative paths\n",
    "image_paths = [os.path.join(base_path, path) for path in image_paths]\n",
    "\n",
    "\n",
    "# Define a custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.brown_color = (115, 70, 31)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.vflip(image)\n",
    "                # Swap labels if vertical flip occurs\n",
    "                if label == 1:\n",
    "                    label = 2\n",
    "                elif label == 2:\n",
    "                    label = 1\n",
    "            if np.random.rand() > 0.5:\n",
    "                \n",
    "                image_np = np.array(image)\n",
    "\n",
    "                # Define the grey color range.\n",
    "                lower_grey = np.array([100, 100, 100])\n",
    "                upper_grey = np.array([200, 200, 200])\n",
    "\n",
    "                # Create a mask for grey areas.\n",
    "                mask = np.all(image_np >= lower_grey, axis=-1) & np.all(image_np <= upper_grey, axis=-1)\n",
    "\n",
    "                # Change grey areas to brown.\n",
    "                image_np[mask] = self.brown_color\n",
    "\n",
    "                image = Image.fromarray(image_np)\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "# Define the data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create the dataset and data loader\n",
    "dataset = CustomDataset(image_paths=image_paths, labels=discrete_labels, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function to visualize the first 30 images with labels\n",
    "def visualize_images(dataloader, num_images=30):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    images_shown = 0\n",
    "    for images, labels in dataloader:\n",
    "        for i in range(images.shape[0]):\n",
    "            if images_shown>= num_images:\n",
    "                break\n",
    "            ax = plt.subplot(6,5, images_shown + 1)\n",
    "            image = images[i].permute(1, 2, 0).numpy()\n",
    "            plt.imshow(image)\n",
    "            plt.title(str(labels[i].item()))\n",
    "            plt.axis(\"off\")\n",
    "            images_shown += 1\n",
    "        if images_shown>= num_images:\n",
    "                break\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize the first 30 images with their labels\n",
    "visualize_images(dataloader, num_images=30)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gymenv)",
   "language": "python",
   "name": "gymenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
