{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Assignment 2: Autonomous Driving (Part 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "#  C:\\Users\\Admin\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\box2d>"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, the goal is to prepare training data for learning to drive autonomously. The assignment will be conducted only on simulated data. For that reason, We will use two simulator examples from [Gym](https://www.gymlibrary.dev/). Gym is a framework for developing reinforcement learning approaches. It supports different types of agents. Here, we will focus on vehicles.\n",
    "\n",
    "*Important*: You need to install [Gym](https://www.gymlibrary.dev/) in your system. The installation can be done with pip or conda. It is highly recommended to install with anaconda on python <=3.11 using the following command: `  conda install conda-forge::gymnasium-box2d `. More information at [https://gym.openai.com/docs/#installation](https://github.com/openai/gym?tab=readme-ov-file#installation).\n",
    "\n",
    "Note that all scripts should be self-contained and executed on *any* machine that has required libraries installed.\n",
    "\n",
    "The solutions of the assignment can be delivered as Python Notebooks or .py files. The visual results can delivered as pdf- or image-files.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "gif_url = 'https://www.gymlibrary.dev/_images/car_racing.gif'\n",
    "\n",
    "response = requests.get(gif_url)\n",
    "\n",
    "with open('mygif.gif', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "display(Image(filename='mygif.gif'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Car Racing Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, a car drives a route in a racing environment. The car can turn left, right, accelerate or decelerate. The input is an image with 96x96 pixels. In addition, rewards are given based on the driving behavior. We are not interested in the rewards in this task. The task of this exercise is to make use of the demo code for driving the racing car and produce training data.\n",
    " \n",
    "*Task Output*: A training set of 5000 images should be generated in this task. You can make of the [car_racing.py](https://github.com/openai/gym/blob/master/gym/envs/box2d/car_racing.py) example from the [Gym examples](https://www.gymlibrary.dev/environments/box2d/car_racing/)  to setup a playing simulator. By playing the in the simulator, you could create 5000 frames and corresponding ground-truth. The ground-truth is simply the control option. The ground-truth can be stored as one-hot vector. The data should include diversity because they will be later used for training a deep neural network.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**. The data augmentation should be dinamically implemented, i.e it is applied when the data from the mini-batch is loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, the generated caring car data and the respective ground-truth data will be visualized (e.g. the first 30 images). The visualization should take place after representing the data in PyTorch format. In addition, horizontal and vertical data augmentation should be implemented in the data loader. Finally, an additional augmentation for changing the street color from gray to brown should be implemented too.\n",
    "\n",
    "*Task Output*: A data loader with horizontal, vertical and street color augmentation should be programmed. In addition, the visualization will show the images and data. Finally, it should be able to turn on / off each augmentation.\n",
    "\n",
    "*Important*: The scripts should be **self-contained**. The data augmentation should be dinamically implemented, i.e it is applied when the data from the mini-batch is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r\"C:\\Users\\Admin\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\box2d\\action_snapshots0.xlsx\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "image_paths = df['Snapshot'].values\n",
    "labels = df['Action'].apply(eval).values\n",
    "\n",
    "def transform_label(label):\n",
    "    if label == [0.0, 0.0, 0.0]:\n",
    "        return 0\n",
    "    elif label == [-1.0, 0.0, 0.0]:\n",
    "        return 1\n",
    "    elif label == [1.0, 0.0, 0.0]:\n",
    "        return 2\n",
    "    elif label == [0.0, 1.0, 0.0]:\n",
    "        return 3\n",
    "    elif label == [0.0, 0.0, 0.8]:\n",
    "        return 4\n",
    "    elif sum([1 for i in label if i != 0.0]) > 1:\n",
    "        return 5\n",
    "    else:\n",
    "        return 0  # Default to 0 if none of the above conditions match\n",
    "\n",
    "\n",
    "discrete_labels = np.array([transform_label(label) for label in labels])\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Path: {image_paths[i]}, Label: {discrete_labels[i]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure image paths are strings\n",
    "image_paths = [str(path) for path in image_paths]\n",
    "\n",
    "# Convert the paths to absolute paths if necessary\n",
    "base_path = r'C:\\Users\\Admin\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\box2d'  # Replace with the base path of your relative paths\n",
    "image_paths = [os.path.join(base_path, path) for path in image_paths]\n",
    "\n",
    "\n",
    "# Define a custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.brown_color = (115, 70, 31)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = transforms.functional.vflip(image)\n",
    "                # Swap labels if vertical flip occurs\n",
    "                if label == 1:\n",
    "                    label = 2\n",
    "                elif label == 2:\n",
    "                    label = 1\n",
    "            if np.random.rand() > 0.5:\n",
    "                \n",
    "                image_np = np.array(image)\n",
    "\n",
    "                # Define the grey color range.\n",
    "                lower_grey = np.array([100, 100, 100])\n",
    "                upper_grey = np.array([200, 200, 200])\n",
    "\n",
    "                # Create a mask for grey areas.\n",
    "                mask = np.all(image_np >= lower_grey, axis=-1) & np.all(image_np <= upper_grey, axis=-1)\n",
    "\n",
    "                # Change grey areas to brown.\n",
    "                image_np[mask] = self.brown_color\n",
    "\n",
    "                image = Image.fromarray(image_np)\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "# Define the data augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create the dataset and data loader\n",
    "dataset = CustomDataset(image_paths=image_paths, labels=discrete_labels, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function to visualize the first 30 images with labels\n",
    "def visualize_images(dataloader, num_images=30):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    images_shown = 0\n",
    "    for images, labels in dataloader:\n",
    "        for i in range(images.shape[0]):\n",
    "            if images_shown>= num_images:\n",
    "                break\n",
    "            ax = plt.subplot(6,5, images_shown + 1)\n",
    "            image = images[i].permute(1, 2, 0).numpy()\n",
    "            plt.imshow(image)\n",
    "            plt.title(str(labels[i].item()))\n",
    "            plt.axis(\"off\")\n",
    "            images_shown += 1\n",
    "        if images_shown>= num_images:\n",
    "                break\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize the first 30 images with their labels\n",
    "visualize_images(dataloader, num_images=30)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imitation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, research on the topic of imitation learning will be conducted. The goal is to understand to concept because it will the main tool for development in the next exercise.\n",
    "\n",
    "*Task Output*: What is imitation learning? How does compare with Guided Policy Search (i.e. reinforcment learning)? What are the advantages and disadvantages of the imitation learning? A short answer for each question in PDF format should be provided.\n",
    "\n",
    "*Referernces*: [End-to-end Driving via Conditional Imitation Learning](https://arxiv.org/abs/1710.02410), [Guided Policy Search](https://graphics.stanford.edu/projects/gpspaper/gps_full.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gymenv)",
   "language": "python",
   "name": "gymenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
